{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(good_l):4058\n"
     ]
    }
   ],
   "source": [
    "# %%writefile 基于opencv特征点检测的图像拼接.py\n",
    "class stitcher:\n",
    "    @staticmethod\n",
    "    def detect(cv_im_bgr):\n",
    "        # 转换为灰度图像\n",
    "        cv_im_gray = cv2.cvtColor(cv_im_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        # sift = cv2.SIFI_create()\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        kps, features = sift.detectAndCompute(cv_im_gray, None)\n",
    "        return kps, features\n",
    "    @staticmethod\n",
    "    def match(cv_im_bgr1, cv_im_bgr2):\n",
    "        kps1, feats1 = stitcher.detect(cv_im_bgr1)\n",
    "        kps2, feats2 = stitcher.detect(cv_im_bgr2)\n",
    "        matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "        matches = matcher.knnMatch(feats1,  # 查询图像的特征描述符\n",
    "                                   feats2,  # 训练图像（数据库图像）的特征描述符\n",
    "                                   k=2)     # 查询图像的每个特征点要在训练图像中找到2个最佳匹配\n",
    "        \n",
    "        return kps1,kps2,matches  \n",
    "    @staticmethod\n",
    "    def match_keypoints(kps1,kps2,matches,ratio,threshold):\n",
    "        \n",
    "        # step1: 筛选匹配点\n",
    "        good_l,matches_l = [], []\n",
    "        for match in matches:\n",
    "            #                            可见匹配的2个点还是有从 优秀-->次优秀排序的。 \n",
    "            #                            如果ratio=0.8，那么对于一个（最优）匹配点，只有当它和它的下一个匹配点（次优）距离小于它的前一个匹配点距离的0.8倍时，才被保留。\n",
    "            if len(match) == 2 and match[0].distance < match[1].distance * ratio:\n",
    "                good_l.append(match[0])\n",
    "                matches_l.append((match[0].queryIdx, match[0].trainIdx)) # （查询图像中点的索引，训练图像中点的索引）\n",
    "        \n",
    "        # 当匹配的特征点对数 > 4,就可以用来构建变换矩阵了\n",
    "        \n",
    "        kps1_coors = np.float32([kpt.pt for kpt in kps1]).tolist()\n",
    "        kps2_coors = np.float32([kpt.pt for kpt in kps2]).tolist()\n",
    "        print(f\"len(good_l):{len(good_l)}\")\n",
    "        if len(good_l) > 4:\n",
    "           def show_match_res(im1, im2, pt1, pt2, matches):\n",
    "               \"\"\" im1: 查询图\n",
    "               im2: 目标图\n",
    "               pt1: 查询图像的 特征点坐标 列表\n",
    "               pt2: 目标图像的 特征点坐标 列表\n",
    "               matches: 匹配点对\n",
    "                  \n",
    "               \"\"\"\n",
    "               im1_h, im1_w = im1.shape[:2]\n",
    "               im2_h, im2_w = im2.shape[:2]\n",
    "               canvas = np.zeros((max(im1_h, im2_h), im1_w + im2_w, 3), dtype=np.uint8)\n",
    "               canvas[:im1_h, :im1_w] = im1\n",
    "               canvas[:im2_h, im1_w:] = im2\n",
    "               \n",
    "               for match in matches:\n",
    "                   # 获取匹配点的坐标\n",
    "                   # (x1, y1) = kps1_coors[match.queryIdx].pt\n",
    "                   # (x2, y2) = kps2_coors[match.trainIdx].pt\n",
    "                   query_point = pt1[match.queryIdx].pt\n",
    "                   train_point = pt2[match.trainIdx].pt\n",
    "                   train_point[0] = train_point[0] + im1_w\n",
    "                   # 绘制匹配点\n",
    "                   cv2.circle(canvas, (int(query_point[0]), int(query_point[1])), 2, (0, 0, 255), -1)\n",
    "                   cv2.circle(canvas, (int(query_point[0]), int(query_point[1])), 2, (0, 0, 255), -1)\n",
    "                   cv2.line(canvas, pt1, pt2, (0, 255, 0), 1) \n",
    "                   \n",
    "                \n",
    "           match_kp1_l =  [kps1_coors[match[0]] for match in matches_l]\n",
    "           match_kp2_l =  [kps2_coors[match[1]] for match in matches_l]\n",
    "           # 计算变换矩阵(采用ransac算法从pts中选择一部分点) ==================> H作用：将原图像转换为目标图像\n",
    "           H, status = cv2.findHomography(np.array(match_kp1_l), # 源图像上的点集\n",
    "                                          np.array(match_kp2_l), # 目标图像上的点集\n",
    "                                          cv2.RANSAC, threshold)\n",
    "        \n",
    "           return H,status, good_l\n",
    "        return None,None,None\n",
    "    \n",
    "    @staticmethod\n",
    "    def stitch(cv_im_bgr1, cv_im_bgr2, H, threshold=10):\n",
    "        \"\"\"\n",
    "        cv_im_bgr1: 源图像， cv_im_bgr2: 目标图像， H: 源图像到目标图像的变换矩阵\n",
    "        \"\"\"\n",
    "        # 获取图像尺寸\n",
    "        src_h, src_w = cv_im_bgr1.shape[:2]\n",
    "        dst_h, dst_w = cv_im_bgr2.shape[:2]\n",
    "        # 对源图像做透视变换，由于透视变换会改变图像的尺寸，导致部分图像内容看不到，所以对图像进行扩展：\n",
    "        # 高度取2图像中最高的，宽度为2者相加\n",
    "        image = np.zeros((max(src_h, dst_h), src_w + dst_w + src_w , 3), dtype=np.uint8)\n",
    "        image[:src_h, src_w//3:src_w+src_w//3]= cv_im_bgr1\n",
    "        image = cv2.warpPerspective(image,\n",
    "                                    H, \n",
    "                                    (image.shape[1], image.shape[0])) # 输出图像的尺寸，非图像内容区域用黑色像素填充\n",
    "        image[0:dst_h, src_w//3:dst_w+src_w//3] = cv_im_bgr2\n",
    "        \n",
    "        ################################## 去掉黑边 begin######################################\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        cols = gray.mean(axis=0)  # 计算每一列的平均像素值\n",
    "        start_col = np.where(cols > threshold)[0][0]  # 找到第一个非黑边的列\n",
    "        end_col = np.where(cols > threshold)[0][-1]   # 找到最后一个非黑边的列\n",
    "        image = image[:, start_col:end_col]\n",
    "        ################################## 去掉黑边 begin######################################\n",
    "        return image\n",
    "    \n",
    "    # @staticmethod\n",
    "    # def show_match_res(im1, im2, matches):\n",
    "    #     for match in matcher:\n",
    "            \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def do(src_cv_im_bgr, dst_cv_im_bgr, ratio=0.80, threshold=3):\n",
    "        kps1,kps2,matches =stitcher.match(src_cv_im_bgr, dst_cv_im_bgr)\n",
    "        H,status, good = stitcher.match_keypoints(kps1,kps2,matches,ratio,threshold)\n",
    "        #####  -------------- 展示拼接效果 begin ------------------ #####\n",
    "        \n",
    "        #####  -------------- 展示拼接效果 end -------------------- #####\n",
    "        if H is not None:\n",
    "            return stitcher.stitch(src_cv_im_bgr, dst_cv_im_bgr, H)\n",
    "        return None\n",
    "#------------------------------------------------------------------------------------- 调用-------------------------------------------------------------------------------------\n",
    "# img0_pth = \"/mnt/disk2/projects/expore/LoFTR-train/assets/books/wz0602001-1.jpg\"\n",
    "# img1_pth = \"/mnt/disk2/projects/expore/LoFTR-train/assets/books/wz0602001-2.jpg\"\n",
    "# img0_pth = r\"/mnt/disk3/projects/expore/accelerated_features/assets/books/wz0602001-01-02.jpg\"\n",
    "# img1_pth = r\"/mnt/disk3/projects/expore/accelerated_features/assets/books/wz0602001-01-03.jpg\"\n",
    "\n",
    "img0_pth = r'/mnt/disk3/projects/expore/accelerated_features/notebooks/n0101001-03/n0101001-03-01.jpg'\n",
    "img1_pth = r'/mnt/disk3/projects/expore/accelerated_features/notebooks/n0101001-03/n0101001-03-02.jpg'\n",
    "src_im = cv2.imread(img0_pth)\n",
    "dst_im = cv2.imread(img1_pth)\n",
    "stitch_im = stitcher.do(src_im, dst_im)\n",
    "if stitch_im is not None:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cv2.cvtColor(stitch_im, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_im = cv2.imread(img0_pth)\n",
    "cv_im_gray = cv2.cvtColor(src_im, cv2.COLOR_BGR2GRAY)\n",
    "# sift = cv2.SIFI_create()\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kps, features = sift.detectAndCompute(cv_im_gray, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((< cv2.KeyPoint 0x7f330adf4e70>, < cv2.KeyPoint 0x7f3309d1a570>),\n",
       " array([[ 22.,  21.,   4.,  14.,  44.,   9.,   3.,   4.,  76.,  13.,   2.,\n",
       "          13.,  98.,  17.,   3.,  16., 206.,  33.,   0.,   0.,   1.,   1.,\n",
       "           1.,  35., 160.,   7.,   0.,   0.,   0.,   0.,   0.,   6.,  12.,\n",
       "           8.,   2.,  19.,  64.,   9.,   8.,  13., 102.,  23.,   7.,  42.,\n",
       "          75.,   9.,   2.,  11., 206.,  33.,   2.,   1.,   0.,   0.,   1.,\n",
       "          50., 169.,   4.,   0.,   0.,   0.,   0.,   1.,  23.,  26.,  10.,\n",
       "           3.,  28.,  76.,  24.,   4.,   9.,  72.,  11.,   5.,  28.,  71.,\n",
       "          28.,  10.,  33., 206.,  40.,   0.,   0.,   0.,   0.,   2.,  28.,\n",
       "          54.,   9.,   0.,   0.,   0.,   0.,   0.,   1.,  17.,  14.,  10.,\n",
       "          43.,  26.,   1.,   0.,   2.,   5.,   3.,   3.,  20.,  13.,   0.,\n",
       "           0.,   2.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 23.,  42.,  16., 134.,  79.,   0.,   0.,   0., 135., 135.,   8.,\n",
       "           8.,   1.,   0.,   0.,   4.,  28.,  20.,   5.,  21.,   7.,   5.,\n",
       "           2.,   2.,   0.,   0.,   2.,  99.,  57.,   3.,   2.,   0.,  40.,\n",
       "          25.,   5., 120., 114.,   2.,   2.,  18., 135., 103.,   4.,   8.,\n",
       "           2.,   0.,   1.,  44.,  62.,  23.,  28., 135.,  19.,   0.,   0.,\n",
       "           3.,   0.,   0.,  21.,  90.,  29.,   0.,   0.,   0.,  14.,   0.,\n",
       "           0.,  27.,  50.,   9.,  52., 135., 116.,   3.,   1.,   6.,  12.,\n",
       "           7.,  27., 135.,  20.,   1.,   3.,  62.,  66.,   9.,   2.,  12.,\n",
       "           0.,   0.,   3.,  11.,   3.,   0.,   0.,   0.,  33.,   1.,   7.,\n",
       "           7.,   6.,   2.,  14., 135.,   4.,  10.,  21.,   5.,   3.,   4.,\n",
       "          10.,  56.,   0.,   0.,   0.,   0.,   3.,   4.,   1.,   1.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32),\n",
       " 52493,\n",
       " 52493)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kps[:2], features[:2], len(kps), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.KeyPoint 0x7f330adf4e70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.82157897949219"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kps[0].angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps[0].angle=90.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.12000274658203"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kps[0].angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal (839784415.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    size=1, angle=-1, response=1, octave=0, class_id=-1\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal\n"
     ]
    }
   ],
   "source": [
    "size=1, angle=-1, response=1, octave=0, class_id=-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfeat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

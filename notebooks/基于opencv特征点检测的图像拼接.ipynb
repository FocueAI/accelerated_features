{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 基于opencv特征点检测的图像拼接.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 基于opencv特征点检测的图像拼接.py\n",
    "class stitcher:\n",
    "    @staticmethod\n",
    "    def detect(cv_im_bgr):\n",
    "        # 转换为灰度图像\n",
    "        cv_im_gray = cv2.cvtColor(cv_im_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        # sift = cv2.SIFI_create()\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        kps, features = sift.detectAndCompute(cv_im_gray, None)\n",
    "        return kps, features\n",
    "    @staticmethod\n",
    "    def match(cv_im_bgr1, cv_im_bgr2):\n",
    "        kps1, feats1 = stitcher.detect(cv_im_bgr1)\n",
    "        kps2, feats2 = stitcher.detect(cv_im_bgr2)\n",
    "        matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "        matches = matcher.knnMatch(feats1,  # 查询图像的特征描述符\n",
    "                                   feats2,  # 训练图像（数据库图像）的特征描述符\n",
    "                                   k=2)     # 查询图像的每个特征点要在训练图像中找到2个最佳匹配\n",
    "        \n",
    "        return kps1,kps2,matches  \n",
    "    @staticmethod\n",
    "    def match_keypoints(kps1,kps2,matches,ratio,threshold):\n",
    "        \n",
    "        # step1: 筛选匹配点\n",
    "        good_l,matches_l = [], []\n",
    "        for match in matches:\n",
    "            #                            可见匹配的2个点还是有从 优秀-->次优秀排序的。 \n",
    "            #                            如果ratio=0.8，那么对于一个（最优）匹配点，只有当它和它的下一个匹配点（次优）距离小于它的前一个匹配点距离的0.8倍时，才被保留。\n",
    "            if len(match) == 2 and match[0].distance < match[1].distance * ratio:\n",
    "                good_l.append(match[0])\n",
    "                matches_l.append((match[0].queryIdx, match[0].trainIdx)) # （查询图像中点的索引，训练图像中点的索引）\n",
    "        \n",
    "        # 当匹配的特征点对数 > 4,就可以用来构建变换矩阵了\n",
    "        \n",
    "        kps1_coors = np.float32([kpt.pt for kpt in kps1]).tolist()\n",
    "        kps2_coors = np.float32([kpt.pt for kpt in kps2]).tolist()\n",
    "        print(f\"len(good_l):{len(good_l)}\")\n",
    "        if len(good_l) > 4:\n",
    "           match_kp1_l =  [kps1_coors[match[0]] for match in matches_l]\n",
    "           match_kp2_l =  [kps2_coors[match[1]] for match in matches_l]\n",
    "           # 计算变换矩阵(采用ransac算法从pts中选择一部分点) ==================> H作用：将原图像转换为目标图像\n",
    "           H, status = cv2.findHomography(np.array(match_kp1_l), # 源图像上的点集\n",
    "                                          np.array(match_kp2_l), # 目标图像上的点集\n",
    "                                          cv2.RANSAC, threshold)\n",
    "        \n",
    "           return H,status, good_l\n",
    "        return None,None,None\n",
    "    \n",
    "    @staticmethod\n",
    "    def stitch(cv_im_bgr1, cv_im_bgr2, H, threshold=10):\n",
    "        \"\"\"\n",
    "        cv_im_bgr1: 源图像， cv_im_bgr2: 目标图像， H: 源图像到目标图像的变换矩阵\n",
    "        \"\"\"\n",
    "        # 获取图像尺寸\n",
    "        src_h, src_w = cv_im_bgr1.shape[:2]\n",
    "        dst_h, dst_w = cv_im_bgr2.shape[:2]\n",
    "        # 对源图像做透视变换，由于透视变换会改变图像的尺寸，导致部分图像内容看不到，所以对图像进行扩展：\n",
    "        # 高度取2图像中最高的，宽度为2者相加\n",
    "        image = np.zeros((max(src_h, dst_h), src_w + dst_w + src_w , 3), dtype=np.uint8)\n",
    "        image[:src_h, src_w//3:src_w+src_w//3]= cv_im_bgr1\n",
    "        image = cv2.warpPerspective(image,\n",
    "                                    H, \n",
    "                                    (image.shape[1], image.shape[0])) # 输出图像的尺寸，非图像内容区域用黑色像素填充\n",
    "        image[0:dst_h, src_w//3:dst_w+src_w//3] = cv_im_bgr2\n",
    "        \n",
    "        ################################## 去掉黑边 begin######################################\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        cols = gray.mean(axis=0)  # 计算每一列的平均像素值\n",
    "        start_col = np.where(cols > threshold)[0][0]  # 找到第一个非黑边的列\n",
    "        end_col = np.where(cols > threshold)[0][-1]   # 找到最后一个非黑边的列\n",
    "        image = image[:, start_col:end_col]\n",
    "        ################################## 去掉黑边 begin######################################\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def do(src_cv_im_bgr, dst_cv_im_bgr, ratio=0.8, threshold=3):\n",
    "        kps1,kps2,matches =stitcher.match(src_cv_im_bgr, dst_cv_im_bgr)\n",
    "        H,status, good = stitcher.match_keypoints(kps1,kps2,matches,ratio,threshold)\n",
    "        if H is not None:\n",
    "            return stitcher.stitch(src_cv_im_bgr, dst_cv_im_bgr, H)\n",
    "        return None\n",
    "#------------------------------------------------------------------------------------- 调用-------------------------------------------------------------------------------------\n",
    "img0_pth = \"/mnt/disk2/projects/expore/LoFTR-train/assets/books/wz0602001-1.jpg\"\n",
    "img1_pth = \"/mnt/disk2/projects/expore/LoFTR-train/assets/books/wz0602001-2.jpg\"\n",
    "src_im = cv2.imread(img0_pth)\n",
    "dst_im = cv2.imread(img1_pth)\n",
    "stitch_im = stitcher.do(src_im, dst_im)\n",
    "if stitch_im is not None:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cv2.cvtColor(stitch_im, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfeat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

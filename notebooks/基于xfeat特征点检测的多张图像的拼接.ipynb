{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from: /mnt/disk3/projects/expore/accelerated_features/weights/xfeat.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/envs/xfeat/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "import torch\n",
    "import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "__dir__ = pathlib.Path(current_directory)\n",
    "sys.path.append(str(__dir__.parent))\n",
    "\n",
    "\n",
    "from modules.xfeat import XFeat\n",
    "\n",
    "weight_path = r'/mnt/disk3/projects/expore/accelerated_features/weights/xfeat.pt'\n",
    "# weight_path = r'/mnt/disk3/projects/expore/accelerated_features/content/ckpts_1_23/xfeat_synthetic_160000.pth'\n",
    "xfeat = XFeat(weights=weight_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img-path-list: ['n0101001-03-01.jpg', 'n0101001-03-02.jpg', 'n0101001-03-03.jpg']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 102\u001b[0m\n\u001b[1;32m     92\u001b[0m im_l \u001b[38;5;241m=\u001b[39m [cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_dir,i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m img_path_l]\u001b[38;5;66;03m#[:2]\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# left_img = im_l[0]\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# other_im_l = im_l[1:]\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# for im in other_im_l:\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#     stitch_im = stitcher.do(left_img, im)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#     left_img = stitch_im\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#     # break\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m stitch_im \u001b[38;5;241m=\u001b[39m \u001b[43mstitcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_cv_im_bgr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mim_l\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdst_cv_im_bgr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mim_l\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# stitch_im = stitcher.do(src_cv_im_bgr=im_l[2],dst_cv_im_bgr=stitch_im)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stitch_im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[2], line 80\u001b[0m, in \u001b[0;36mstitcher.do\u001b[0;34m(src_cv_im_bgr, dst_cv_im_bgr, ratio, threshold)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(src_cv_im_bgr, dst_cv_im_bgr, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 80\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[43mstitcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_cv_im_bgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_cv_im_bgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# H,status, good = stitcher.match_keypoints(kps1,kps2,matches,ratio,threshold)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m H \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mstitcher.match\u001b[0;34m(src_cv_img, dst_cv_img, threshold)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(src_cv_img, dst_cv_img, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.0\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# ------------------------------- begin ------------------------------------\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     kps1, feats1 \u001b[38;5;241m=\u001b[39m \u001b[43mstitcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_cv_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     kps2, feats2 \u001b[38;5;241m=\u001b[39m stitcher\u001b[38;5;241m.\u001b[39mdetect(dst_cv_img)\n\u001b[1;32m     15\u001b[0m     src_index, dst_index \u001b[38;5;241m=\u001b[39m xfeat\u001b[38;5;241m.\u001b[39mmatch(feats1, feats2, min_cossim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mstitcher.detect\u001b[0;34m(cv_im_bgr)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(cv_im_bgr):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m################################################### \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# res = xfeat.detectAndCompute(cv_im_bgr)[0]\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     res1 \u001b[38;5;241m=\u001b[39m \u001b[43mxfeat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectAndComputeDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_im_bgr\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     kps, features \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m], res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescriptors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kps, features\n",
      "File \u001b[0;32m~/anaconda3/envs/xfeat/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/disk3/projects/expore/accelerated_features/modules/xfeat.py:121\u001b[0m, in \u001b[0;36mXFeat.detectAndComputeDense\u001b[0;34m(self, x, top_k, multiscale)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multiscale:\n\u001b[0;32m--> 121\u001b[0m \tmkpts, sc, feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_dualscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m \tmkpts, feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractDense(x, top_k)\n",
      "File \u001b[0;32m/mnt/disk3/projects/expore/accelerated_features/modules/xfeat.py:380\u001b[0m, in \u001b[0;36mXFeat.extract_dualscale\u001b[0;34m(self, x, top_k, s1, s2)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_dualscale\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, top_k, s1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m, s2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.3\u001b[39m):\n\u001b[0;32m--> 380\u001b[0m \tx1 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \tx2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, scale_factor\u001b[38;5;241m=\u001b[39ms2, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    383\u001b[0m \tB, _, _, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/xfeat/lib/python3.9/site-packages/torch/nn/functional.py:3921\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3919\u001b[0m         align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3921\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Number of spatial dimensions.\u001b[39;00m\n\u001b[1;32m   3923\u001b[0m \u001b[38;5;66;03m# Process size and scale_factor.  Validate that exactly one is set.\u001b[39;00m\n\u001b[1;32m   3924\u001b[0m \u001b[38;5;66;03m# Validate its length if it is a list, or expand it if it is a scalar.\u001b[39;00m\n\u001b[1;32m   3925\u001b[0m \u001b[38;5;66;03m# After this block, exactly one of output_size and scale_factors will\u001b[39;00m\n\u001b[1;32m   3926\u001b[0m \u001b[38;5;66;03m# be non-None, and it will be a list (or tuple).\u001b[39;00m\n\u001b[1;32m   3927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scale_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "class stitcher:\n",
    "    @staticmethod\n",
    "    def detect(cv_im_bgr):\n",
    "        ################################################### \n",
    "        # res = xfeat.detectAndCompute(cv_im_bgr)[0]\n",
    "        res1 = xfeat.detectAndComputeDense(cv_im_bgr)[0]\n",
    "        kps, features = res[\"keypoints\"], res[\"descriptors\"]\n",
    "        \n",
    "        return kps, features\n",
    "    @staticmethod\n",
    "    def match(src_cv_img, dst_cv_img, threshold=3.0):\n",
    "        # ------------------------------- begin ------------------------------------\n",
    "        kps1, feats1 = stitcher.detect(src_cv_img)\n",
    "        kps2, feats2 = stitcher.detect(dst_cv_img)\n",
    "        src_index, dst_index = xfeat.match(feats1, feats2, min_cossim = 0.9)\n",
    "        src_points, dst_points = kps1[src_index].cpu().numpy(), kps2[dst_index].cpu().numpy()\n",
    "        H, status = cv2.findHomography(src_points, # 源图像上的点集\n",
    "                                dst_points, # 目标图像上的点集\n",
    "                                cv2.RANSAC, threshold)\n",
    "        # 其中 H 表示源图像到目标图像的变换矩阵\n",
    "        return H\n",
    "\n",
    "    @staticmethod\n",
    "    def match_keypoints(kps1,kps2,matches,ratio,threshold):\n",
    "        \n",
    "        # step1: 筛选匹配点\n",
    "        good_l,matches_l = [], []\n",
    "        for match in matches:\n",
    "            #                            可见匹配的2个点还是有从 优秀-->次优秀排序的。 \n",
    "            #                            如果ratio=0.8，那么对于一个（最优）匹配点，只有当它和它的下一个匹配点（次优）距离小于它的前一个匹配点距离的0.8倍时，才被保留。\n",
    "            if len(match) == 2 and match[0].distance < match[1].distance * ratio:\n",
    "                good_l.append(match[0])\n",
    "                matches_l.append((match[0].queryIdx, match[0].trainIdx)) # （查询图像中点的索引，训练图像中点的索引）\n",
    "        \n",
    "        # 当匹配的特征点对数 > 4,就可以用来构建变换矩阵了\n",
    "        \n",
    "        kps1_coors = np.float32([kpt.pt for kpt in kps1]).tolist()\n",
    "        kps2_coors = np.float32([kpt.pt for kpt in kps2]).tolist()\n",
    "        print(f\"len(good_l):{len(good_l)}\")\n",
    "        if len(good_l) > 4:\n",
    "           match_kp1_l =  [kps1_coors[match[0]] for match in matches_l]\n",
    "           match_kp2_l =  [kps2_coors[match[1]] for match in matches_l]\n",
    "           # 计算变换矩阵(采用ransac算法从pts中选择一部分点) ==================> H作用：将原图像转换为目标图像\n",
    "           H, status = cv2.findHomography(np.array(match_kp1_l), # 源图像上的点集\n",
    "                                          np.array(match_kp2_l), # 目标图像上的点集\n",
    "                                          cv2.RANSAC, threshold)\n",
    "        \n",
    "           return H,status, good_l\n",
    "        return None,None,None\n",
    "    \n",
    "    @staticmethod\n",
    "    def stitch(src_cv_im_bgr1, dst_cv_im_bgr2, H, threshold=10):\n",
    "        \"\"\"\n",
    "        src_cv_im_bgr1: 源图像， dst_cv_im_bgr2: 目标图像， H: 源图像到目标图像的变换矩阵\n",
    "        \"\"\"\n",
    "        # 获取图像尺寸\n",
    "        src_h, src_w = src_cv_im_bgr1.shape[:2]\n",
    "        dst_h, dst_w = dst_cv_im_bgr2.shape[:2]\n",
    "        # 对源图像做透视变换，由于透视变换会改变图像的尺寸，导致部分图像内容看不到，所以对图像进行扩展：\n",
    "        # 高度取2图像中最高的，宽度为2者相加\n",
    "        image = np.zeros((max(src_h, dst_h), src_w + dst_w + src_w , 3), dtype=np.uint8)\n",
    "        image[:src_h, src_w//3:src_w+src_w//3]= src_cv_im_bgr1\n",
    "        image = cv2.warpPerspective(image,\n",
    "                                    H, \n",
    "                                    (image.shape[1], image.shape[0])) # 输出图像的尺寸，非图像内容区域用黑色像素填充\n",
    "        image[0:dst_h, src_w//3:dst_w+src_w//3] = dst_cv_im_bgr2 #  源图像不变。。。。。。。。。\n",
    "        \n",
    "        ################################## 去掉黑边 begin######################################\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # cols = gray.mean(axis=0)  # 计算每一列的平均像素值\n",
    "        cols = gray.sum(axis=0)  # 计算每一列的平均像素值\n",
    "        start_col = np.where(cols != 0)[0][0]  # 找到第一个非黑边的列\n",
    "        end_col = np.where(cols !=0 )[0][-1]   # 找到最后一个非黑边的列\n",
    "        image = image[:, start_col:end_col]\n",
    "        ################################## 去掉黑边 begin######################################\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def do(src_cv_im_bgr, dst_cv_im_bgr, ratio=0.8, threshold=3):\n",
    "        H = stitcher.match(src_cv_im_bgr, dst_cv_im_bgr, threshold)\n",
    "        # H,status, good = stitcher.match_keypoints(kps1,kps2,matches,ratio,threshold)\n",
    "        if H is not None:\n",
    "            return stitcher.stitch(src_cv_im_bgr, dst_cv_im_bgr, H)\n",
    "        return None\n",
    "#------------------------------------------------------------------------------------- 调用-------------------------------------------------------------------------------------\n",
    "img_dir = r'./n0101001-03'\n",
    "\n",
    "img_path_l = os.listdir(img_dir)\n",
    "img_path_l = sorted(img_path_l,key=lambda a: int(a.split('-')[-1].replace('.jpg','').replace('.png','')))\n",
    "print(\"img-path-list:\",img_path_l)\n",
    "\n",
    "im_l = [cv2.imread(os.path.join(img_dir,i)) for i in img_path_l]#[:2]\n",
    "# left_img = im_l[0]\n",
    "# other_im_l = im_l[1:]\n",
    "# for im in other_im_l:\n",
    "#     stitch_im = stitcher.do(left_img, im)\n",
    "#     left_img = stitch_im\n",
    "#     # break\n",
    "\n",
    "\n",
    "\n",
    "stitch_im = stitcher.do(src_cv_im_bgr=im_l[0],dst_cv_im_bgr=im_l[1])\n",
    "# stitch_im = stitcher.do(src_cv_im_bgr=im_l[2],dst_cv_im_bgr=stitch_im)\n",
    "if stitch_im is not None:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cv2.cvtColor(stitch_im, cv2.COLOR_BGR2RGB))\n",
    "    # cv2.imwrite(f'/mnt/disk3/projects/expore/accelerated_features/notebooks/results/stitch.jpg',stitch_im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfeat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
